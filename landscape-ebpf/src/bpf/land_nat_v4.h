#ifndef LD_NAT_V4_H
#define LD_NAT_V4_H
#include <vmlinux.h>
#include "landscape_log.h"
#include "pkg_scanner.h"
#include "pkg_fragment.h"
#include "land_nat_common.h"
#include "nat/nat_maps.h"
#include "land_wan_ip.h"

volatile const u16 tcp_range_start = 32768;
// volatile const u16 tcp_range_end = 32770;
volatile const u16 tcp_range_end = 65535;

volatile const u16 udp_range_start = 32768;
volatile const u16 udp_range_end = 65535;

volatile const u16 icmp_range_start = 32768;
volatile const u16 icmp_range_end = 65535;

static __always_inline int icmpx_err_l3_offset(int l4_off) {
    return l4_off + sizeof(struct icmphdr);
}

#define L3_CSUM_REPLACE_OR_SHOT(skb_ptr, csum_offset, old_val, new_val, size)                      \
    do {                                                                                           \
        int _ret = bpf_l3_csum_replace(skb_ptr, csum_offset, old_val, new_val, size);              \
        if (_ret) {                                                                                \
            bpf_printk("l3_csum_replace err: %d", _ret);                                           \
            return TC_ACT_SHOT;                                                                    \
        }                                                                                          \
    } while (0)

#define L4_CSUM_REPLACE_OR_SHOT(skb_ptr, csum_offset, old_val, new_val, len_plus_flags)            \
    do {                                                                                           \
        int _ret = bpf_l4_csum_replace(skb_ptr, csum_offset, old_val, new_val, len_plus_flags);    \
        if (_ret) {                                                                                \
            bpf_printk("l4_csum_replace err: %d", _ret);                                           \
            return TC_ACT_SHOT;                                                                    \
        }                                                                                          \
    } while (0)

static __always_inline int ipv4_update_csum_inner_macro(struct __sk_buff *skb, u32 l4_csum_off,
                                                        __be32 from_addr, __be16 from_port,
                                                        __be32 to_addr, __be16 to_port,
                                                        bool l4_pseudo, bool l4_mangled_0) {
    u16 csum;
    if (l4_mangled_0) {
        READ_SKB_U16(skb, l4_csum_off, csum);
    }

    if (!l4_mangled_0 || csum != 0) {
        L3_CSUM_REPLACE_OR_SHOT(skb, l4_csum_off, from_port, to_port, 2);

        if (l4_pseudo) {
            L3_CSUM_REPLACE_OR_SHOT(skb, l4_csum_off, from_addr, to_addr, 4);
        }
    }
}

static __always_inline int ipv4_update_csum_icmp_err_macro(struct __sk_buff *skb, u32 icmp_csum_off,
                                                           u32 err_ip_check_off,
                                                           u32 err_l4_csum_off, __be32 from_addr,
                                                           __be16 from_port, __be32 to_addr,
                                                           __be16 to_port, bool err_l4_pseudo,
                                                           bool l4_mangled_0) {
    u16 prev_csum;
    u16 curr_csum;
    u16 *tmp_ptr;

    // bpf_skb_load_bytes(skb, err_ip_check_off, &prev_csum, sizeof(prev_csum));
    if (VALIDATE_READ_DATA(skb, &tmp_ptr, err_ip_check_off, sizeof(*tmp_ptr))) {
        return 1;
    }
    prev_csum = *tmp_ptr;

    // 替换原始 L3 校验和 (4 bytes)
    L3_CSUM_REPLACE_OR_SHOT(skb, err_ip_check_off, from_addr, to_addr, 4);

    // bpf_skb_load_bytes(skb, err_ip_check_off, &curr_csum, sizeof(curr_csum));
    if (VALIDATE_READ_DATA(skb, &tmp_ptr, err_ip_check_off, sizeof(*tmp_ptr))) {
        return 1;
    }
    curr_csum = *tmp_ptr;
    L4_CSUM_REPLACE_OR_SHOT(skb, icmp_csum_off, prev_csum, curr_csum, 2);

    // if (bpf_skb_load_bytes(skb, err_l4_csum_off, &prev_csum, sizeof(prev_csum)) == 0) {
    if (VALIDATE_READ_DATA(skb, &tmp_ptr, err_l4_csum_off, sizeof(*tmp_ptr)) == 0) {
        prev_csum = *tmp_ptr;
        ipv4_update_csum_inner_macro(skb, err_l4_csum_off, from_addr, from_port, to_addr, to_port,
                                     err_l4_pseudo, l4_mangled_0);

        // bpf_skb_load_bytes(skb, err_l4_csum_off, &curr_csum, sizeof(curr_csum));
        if (VALIDATE_READ_DATA(skb, &tmp_ptr, err_l4_csum_off, sizeof(*tmp_ptr))) {
            return 1;
        }
        curr_csum = *tmp_ptr;
        L4_CSUM_REPLACE_OR_SHOT(skb, icmp_csum_off, prev_csum, curr_csum, 2);
    }

    L4_CSUM_REPLACE_OR_SHOT(skb, icmp_csum_off, from_addr, to_addr, 4);

    L4_CSUM_REPLACE_OR_SHOT(skb, icmp_csum_off, from_port, to_port, 2);

    return 0;
}

static __always_inline int modify_headers_v4(struct __sk_buff *skb, bool is_icmpx_error, u8 nexthdr,
                                             u32 current_l3_offset, int l4_off, int err_l4_off,
                                             bool is_modify_source,
                                             const struct nat_action_v4 *action) {
#define BPF_LOG_TOPIC "modify_headers_v4"
    int ret;
    int l4_to_port_off;
    int l4_to_check_off;
    bool l4_check_pseudo;
    bool l4_check_mangle_0;

    int ip_offset =
        is_modify_source ? offsetof(struct iphdr, saddr) : offsetof(struct iphdr, daddr);

    ret = bpf_skb_store_bytes(skb, current_l3_offset + ip_offset, &action->to_addr.addr,
                              sizeof(action->to_addr.addr), 0);
    if (ret) return ret;

    L3_CSUM_REPLACE_OR_SHOT(skb, current_l3_offset + offsetof(struct iphdr, check),
                            action->from_addr.addr, action->to_addr.addr, 4);

    if (l4_off == 0) return 0;

    switch (nexthdr) {
    case IPPROTO_TCP:
        l4_to_port_off =
            is_modify_source ? offsetof(struct tcphdr, source) : offsetof(struct tcphdr, dest);
        l4_to_check_off = offsetof(struct tcphdr, check);
        l4_check_pseudo = true;
        l4_check_mangle_0 = false;
        break;
    case IPPROTO_UDP:
        l4_to_port_off =
            is_modify_source ? offsetof(struct udphdr, source) : offsetof(struct udphdr, dest);
        l4_to_check_off = offsetof(struct udphdr, check);
        l4_check_pseudo = true;
        l4_check_mangle_0 = true;
        break;
    case IPPROTO_ICMP:
        l4_to_port_off = offsetof(struct icmphdr, un.echo.id);
        l4_to_check_off = offsetof(struct icmphdr, checksum);
        l4_check_pseudo = false;
        l4_check_mangle_0 = false;
        break;
    default:
        return 1;
    }

    if (is_icmpx_error) {
        if (nexthdr == IPPROTO_TCP || nexthdr == IPPROTO_UDP) {
            l4_to_port_off =
                is_modify_source ? offsetof(struct tcphdr, dest) : offsetof(struct tcphdr, source);
        }

        int icmpx_error_offset =
            is_modify_source ? offsetof(struct iphdr, daddr) : offsetof(struct iphdr, saddr);

        ret = bpf_skb_store_bytes(skb, icmpx_err_l3_offset(l4_off) + icmpx_error_offset,
                                  &action->to_addr.addr, sizeof(action->to_addr.addr), 0);
        if (ret) return ret;

        ret = bpf_write_port(skb, err_l4_off + l4_to_port_off, action->to_port);
        if (ret) return ret;

        if (ipv4_update_csum_icmp_err_macro(
                skb, l4_off + offsetof(struct icmphdr, checksum),
                icmpx_err_l3_offset(l4_off) + offsetof(struct iphdr, check),
                err_l4_off + l4_to_check_off, action->from_addr.addr, action->from_port,
                action->to_addr.addr, action->to_port, l4_check_pseudo, l4_check_mangle_0))
            return TC_ACT_SHOT;

    } else {
        ret = bpf_write_port(skb, l4_off + l4_to_port_off, action->to_port);
        if (ret) return ret;

        u32 l4_csum_off = l4_off + l4_to_check_off;
        u32 flags_mangled = l4_check_mangle_0 ? BPF_F_MARK_MANGLED_0 : 0;

        L4_CSUM_REPLACE_OR_SHOT(skb, l4_csum_off, action->from_port, action->to_port,
                                2 | flags_mangled);

        if (l4_check_pseudo) {
            L4_CSUM_REPLACE_OR_SHOT(skb, l4_csum_off, action->from_addr.addr, action->to_addr.addr,
                                    4 | BPF_F_PSEUDO_HDR | flags_mangled);
        }
    }

    return 0;
#undef BPF_LOG_TOPIC
}

static __always_inline bool try_report() {}

static __always_inline void nat_metric_accumulate(struct __sk_buff *skb, bool ingress,
                                                  struct nat_timer_value_v4 *value) {
    u64 bytes = skb->len;
    if (ingress) {
        __sync_fetch_and_add(&value->ingress_bytes, bytes);
        __sync_fetch_and_add(&value->ingress_packets, 1);
    } else {
        __sync_fetch_and_add(&value->egress_bytes, bytes);
        __sync_fetch_and_add(&value->egress_packets, 1);
    }
}

static __always_inline int nat_metric_try_report_v4(struct nat_timer_key_v4 *timer_key,
                                                    struct nat_timer_value_v4 *timer_value,
                                                    u8 status) {
#define BPF_LOG_TOPIC "nat_metric_try_report_v4"

    struct nat_conn_metric_event *event;
    event = bpf_ringbuf_reserve(&nat_conn_metric_events, sizeof(struct nat_conn_metric_event), 0);
    if (event == NULL) {
        return -1;
    }

    // Ac from value, As from key
    event->src_addr.ip = timer_value->client_addr.addr;
    event->dst_addr.ip = timer_key->pair_ip.src_addr.addr;

    // Pc from value, Ps from key
    event->src_port = timer_value->client_port;
    event->dst_port = timer_key->pair_ip.src_port;

    event->l4_proto = timer_key->l4proto;
    event->l3_proto = LANDSCAPE_IPV4_TYPE;
    event->flow_id = timer_value->flow_id;
    event->trace_id = 0;
    event->time = bpf_ktime_get_ns();
    event->create_time = timer_value->create_time;
    event->ingress_bytes = timer_value->ingress_bytes;
    event->ingress_packets = timer_value->ingress_packets;
    event->egress_bytes = timer_value->egress_bytes;
    event->egress_packets = timer_value->egress_packets;
    event->cpu_id = timer_value->cpu_id;
    event->status = status;
    event->gress = timer_value->gress;
    bpf_ringbuf_submit(event, 0);

    return 0;
#undef BPF_LOG_TOPIC
}

static __always_inline bool ct_change_state(u64 *status_in_value, u64 curr_state, u64 next_state) {
    return __sync_bool_compare_and_swap(status_in_value, curr_state, next_state);
}

static __always_inline int ct_state_transition(u8 l4proto, u8 pkt_type, u8 gress,
                                               struct nat_timer_value_v4 *ct_timer_value) {
#define BPF_LOG_TOPIC "ct_state_transition"
    u64 curr_state, *modify_status = NULL;
    if (gress == NAT_MAPPING_INGRESS) {
        curr_state = ct_timer_value->server_status;
        modify_status = &ct_timer_value->server_status;
    } else {
        curr_state = ct_timer_value->client_status;
        modify_status = &ct_timer_value->client_status;
    }

#define NEW_STATE(__state)                                                                         \
    if (!ct_change_state(modify_status, curr_state, (__state))) {                                  \
        return TC_ACT_SHOT;                                                                        \
    }

    if (pkt_type == PKT_CONNLESS_V2) {
        NEW_STATE(CT_LESS_EST);
    }

    if (pkt_type == PKT_TCP_RST_V2) {
        NEW_STATE(CT_INIT);
    }

    if (pkt_type == PKT_TCP_SYN_V2) {
        NEW_STATE(CT_SYN);
    }

    if (pkt_type == PKT_TCP_FIN_V2) {
        NEW_STATE(CT_FIN);
    }

    u64 prev_state = __sync_lock_test_and_set(&ct_timer_value->status, TIMER_ACTIVE);
    if (prev_state != TIMER_ACTIVE) {
        if (ct_timer_value->client_port == TEST_PORT) {
            bpf_log_info("flush status to TIMER_ACTIVE: 20");
        }
        bpf_timer_start(&ct_timer_value->timer, REPORT_INTERVAL, 0);
    }

    return TC_ACT_OK;
#undef BPF_LOG_TOPIC
}

static int timer_clean_callback(void *map_mapping_timer_, struct nat_timer_key_v4 *key,
                                struct nat_timer_value_v4 *value) {
#define BPF_LOG_TOPIC "timer_clean_callback"

    u64 client_status = value->client_status;
    u64 server_status = value->server_status;
    u64 current_status = value->status;
    u64 next_status = current_status;
    u64 next_timeout = REPORT_INTERVAL;
    int ret;

    if (value->client_port == TEST_PORT) {
        bpf_log_info("timer_clean_callback: %pI4, current_status: %llu", &value->client_addr.addr,
                     current_status);
    }

    if (current_status == TIMER_RELEASE) {
        if (value->client_port == TEST_PORT) {
            bpf_log_info("release CONNECT");
        }

        ret = nat_metric_try_report_v4(key, value, NAT_CONN_DELETE);
        if (ret) {
            bpf_log_info("call back report fail");
            bpf_timer_start(&value->timer, next_timeout, 0);
            return 0;
        }

        goto release;
    }

    ret = nat_metric_try_report_v4(key, value, NAT_CONN_ACTIVE);
    if (ret) {
        bpf_log_info("call back report fail");
        bpf_timer_start(&value->timer, next_timeout, 0);
        return 0;
    }

    if (current_status == TIMER_ACTIVE) {
        next_status = TIMER_TIMEOUT_1;
        next_timeout = REPORT_INTERVAL;

        if (value->client_port == TEST_PORT) {
            bpf_log_info("change next status TIMER_TIMEOUT_1");
        }
    } else if (current_status == TIMER_TIMEOUT_1) {
        next_status = TIMER_TIMEOUT_2;
        next_timeout = REPORT_INTERVAL;

        if (value->client_port == TEST_PORT) {
            bpf_log_info("change next status TIMER_TIMEOUT_2");
        }
    } else if (current_status == TIMER_TIMEOUT_2) {
        next_status = TIMER_RELEASE;
        if (key->l4proto == IPPROTO_TCP) {
            if (client_status == CT_SYN && server_status == CT_SYN) {
                next_timeout = TCP_TIMEOUT;
            } else {
                next_timeout = TCP_SYN_TIMEOUT;
            }
        } else {
            next_timeout = UDP_TIMEOUT;
        }
        if (value->client_port == TEST_PORT) {
            u64 show = (next_timeout / 1000000000ULL);
            bpf_log_info("change next status TIMER_RELEASE, next_timeout: %d", show);
        }
    } else {
        next_status = TIMER_TIMEOUT_2;
        next_timeout = REPORT_INTERVAL;
    }

    if (__sync_val_compare_and_swap(&value->status, current_status, next_status) !=
        current_status) {
        bpf_log_info("call back modify status fail, current status: %d new status: %d",
                     current_status, next_status);
        // 更新状态失败, 说明有新的数据包到达
        bpf_timer_start(&value->timer, REPORT_INTERVAL, 0);
        return 0;
    }

    bpf_timer_start(&value->timer, next_timeout, 0);

    return 0;
release:;
    // egress key: {EGRESS, proto, Pc, Ac} — from value
    struct nat_mapping_key_v4 egress_mapping_key = {0};
    egress_mapping_key.l4proto = key->l4proto;
    egress_mapping_key.gress = NAT_MAPPING_EGRESS;
    egress_mapping_key.from_addr = value->client_addr.addr;
    egress_mapping_key.from_port = value->client_port;

    // ingress key: {INGRESS, proto, Pn, An} — from key
    struct nat_mapping_key_v4 ingress_mapping_key = {0};
    ingress_mapping_key.l4proto = key->l4proto;
    ingress_mapping_key.gress = NAT_MAPPING_INGRESS;
    ingress_mapping_key.from_addr = key->pair_ip.dst_addr.addr;
    ingress_mapping_key.from_port = key->pair_ip.dst_port;

    // Check if static: lookup egress mapping, if is_static don't delete mapping entries
    struct nat_mapping_value_v4 *egress_val =
        bpf_map_lookup_elem(&nat4_mappings, &egress_mapping_key);
    if (!egress_val || !egress_val->is_static) {
        bpf_map_delete_elem(&nat4_mappings, &egress_mapping_key);
        bpf_map_delete_elem(&nat4_mappings, &ingress_mapping_key);
    }

    bpf_map_delete_elem(&nat4_mapping_timer, key);
    return 0;
#undef BPF_LOG_TOPIC
}

static __always_inline struct nat_timer_value_v4 *
insert_new_nat_timer(u8 l4proto, const struct nat_timer_key_v4 *key,
                     const struct nat_timer_value_v4 *val) {
#define BPF_LOG_TOPIC "insert_new_nat_timer"

    int ret = bpf_map_update_elem(&nat4_mapping_timer, key, val, BPF_NOEXIST);
    if (ret) {
        bpf_log_error("failed to insert conntrack entry, err:%d", ret);
        return NULL;
    }
    struct nat_timer_value_v4 *value = bpf_map_lookup_elem(&nat4_mapping_timer, key);
    if (!value) return NULL;

    ret = bpf_timer_init(&value->timer, &nat4_mapping_timer, CLOCK_MONOTONIC);
    if (ret) {
        goto delete_timer;
    }
    ret = bpf_timer_set_callback(&value->timer, timer_clean_callback);
    if (ret) {
        goto delete_timer;
    }
    ret = bpf_timer_start(&value->timer, REPORT_INTERVAL, 0);
    if (ret) {
        goto delete_timer;
    }

    return value;
delete_timer:
    bpf_log_error("setup timer err:%d", ret);
    bpf_map_delete_elem(&nat4_mapping_timer, key);
    return NULL;
#undef BPF_LOG_TOPIC
}

static __always_inline int lookup_or_new_ct(struct __sk_buff *skb, u8 l4proto, bool do_new,
                                            const struct inet4_pair *server_nat_pair,
                                            const struct inet4_addr *client_addr,
                                            __be16 client_port, u8 gress,
                                            struct nat_timer_value_v4 **timer_value_) {
#define BPF_LOG_TOPIC "lookup_or_new_ct"

    struct nat_timer_key_v4 timer_key = {0};
    u8 flow_id = get_flow_id(skb->mark);

    timer_key.l4proto = l4proto;
    // CT key = {As:Ps, An:Pn}
    __builtin_memcpy(&timer_key.pair_ip, server_nat_pair, sizeof(timer_key.pair_ip));

    struct nat_timer_value_v4 *timer_value = bpf_map_lookup_elem(&nat4_mapping_timer, &timer_key);
    if (timer_value) {
        *timer_value_ = timer_value;
        return TIMER_EXIST;
    }
    if (!do_new) {
        return TIMER_NOT_FOUND;
    }

    struct nat_timer_value_v4 timer_value_new = {0};
    timer_value_new.client_port = client_port;
    timer_value_new.client_status = CT_INIT;
    timer_value_new.server_status = CT_INIT;
    timer_value_new.gress = gress;
    timer_value_new.client_addr = *client_addr;
    timer_value_new.create_time = bpf_ktime_get_ns();
    timer_value_new.flow_id = flow_id;
    timer_value_new.cpu_id = bpf_get_smp_processor_id();
    timer_value = insert_new_nat_timer(l4proto, &timer_key, &timer_value_new);
    if (timer_value == NULL) {
        return TIMER_ERROR;
    }

    *timer_value_ = timer_value;
    return TIMER_CREATED;
#undef BPF_LOG_TOPIC
}

static __always_inline struct nat_mapping_value_v4 *
insert_mappings_v4(const struct nat_mapping_key_v4 *key, const struct nat_mapping_value_v4 *val,
                   struct nat_mapping_value_v4 **lk_val_rev) {
#define BPF_LOG_TOPIC "insert_mappings_v4"
    int ret;
    struct nat_mapping_key_v4 key_rev = {
        .gress = key->gress ^ GRESS_MASK,
        .l4proto = key->l4proto,
        .from_addr = val->addr,
        .from_port = val->port,
    };

    struct nat_mapping_value_v4 val_rev = {
        .port = key->from_port,
        .addr = key->from_addr,
        .trigger_addr = val->trigger_addr,
        .trigger_port = val->trigger_port,
        .is_allow_reuse = val->is_allow_reuse,
        .is_static = val->is_static,
        .active_time = val->active_time,
        ._pad = {0, 0},
    };

    ret = bpf_map_update_elem(&nat4_mappings, key, val, BPF_ANY);
    if (ret) {
        bpf_log_error("failed to insert binding entry, err:%d", ret);
        goto error_update;
    }
    ret = bpf_map_update_elem(&nat4_mappings, &key_rev, &val_rev, BPF_ANY);
    if (ret) {
        bpf_log_error("failed to insert reverse binding entry, err:%d", ret);
        goto error_update;
    }

    if (lk_val_rev) {
        *lk_val_rev = bpf_map_lookup_elem(&nat4_mappings, &key_rev);
        if (!*lk_val_rev) {
            return NULL;
        }
    }

    return bpf_map_lookup_elem(&nat4_mappings, key);
error_update:
    bpf_map_delete_elem(&nat4_mappings, key);
    bpf_map_delete_elem(&nat4_mappings, &key_rev);
    return NULL;
#undef BPF_LOG_TOPIC
}

static int search_port_callback_v4(u32 index, struct search_port_ctx_v4 *ctx) {
#define BPF_LOG_TOPIC "search_port_callback_v4"
    ctx->ingress_key.from_port = bpf_htons(ctx->curr_port);
    struct nat_mapping_value_v4 *value = bpf_map_lookup_elem(&nat4_mappings, &ctx->ingress_key);
    // 大于协议的超时时间
    if (!value || ctx->timeout_interval > value->active_time) {
        // Also check addr=0 static mapping to avoid conflict
        struct nat_mapping_key_v4 static_key = {
            .gress = NAT_MAPPING_INGRESS,
            .l4proto = ctx->ingress_key.l4proto,
            .from_port = ctx->ingress_key.from_port,
            .from_addr = 0,
        };
        struct nat_mapping_value_v4 *static_val = bpf_map_lookup_elem(&nat4_mappings, &static_key);
        if (!static_val) {
            ctx->found = true;
            return BPF_LOOP_RET_BREAK;
        }
    }

    if (ctx->curr_port != ctx->range.end) {
        ctx->curr_port++;
    } else {
        ctx->curr_port = ctx->range.start;
    }
    if (--ctx->remaining_size == 0) {
        return BPF_LOOP_RET_BREAK;
    }

    return BPF_LOOP_RET_CONTINUE;
#undef BPF_LOG_TOPIC
}

static __always_inline int
ingress_lookup_or_new_mapping4(struct __sk_buff *skb, u8 ip_protocol,
                               const struct inet4_pair *pkt_ip_pair,
                               struct nat_mapping_value_v4 **nat_ingress_value_) {
#define BPF_LOG_TOPIC "ingress_lookup_or_new_mapping"
    u64 current_time = bpf_ktime_get_ns();
    if (pkt_ip_pair == NULL) {
        return TC_ACT_SHOT;
    }

    // First try exact match: {INGRESS, proto, Pn, An}
    struct nat_mapping_key_v4 ingress_key = {
        .gress = NAT_MAPPING_INGRESS,
        .l4proto = ip_protocol,
        .from_port = pkt_ip_pair->dst_port,
        .from_addr = pkt_ip_pair->dst_addr.addr,
    };

    struct nat_mapping_value_v4 *nat_ingress_value =
        bpf_map_lookup_elem(&nat4_mappings, &ingress_key);

    if (!nat_ingress_value) {
        // Fallback: try addr=0 for static mapping {INGRESS, proto, Pn, 0}
        ingress_key.from_addr = 0;
        nat_ingress_value = bpf_map_lookup_elem(&nat4_mappings, &ingress_key);
        if (!nat_ingress_value) {
            return TC_ACT_SHOT;
        }
    }

    nat_ingress_value->active_time = current_time;

    *nat_ingress_value_ = nat_ingress_value;
    return TC_ACT_OK;
#undef BPF_LOG_TOPIC
}

static __always_inline int
egress_lookup_or_new_mapping_v4(struct __sk_buff *skb, u8 ip_protocol, bool allow_create_mapping,
                                const struct inet4_pair *pkt_ip_pair,
                                struct nat_mapping_value_v4 **nat_egress_value_,
                                struct nat_mapping_value_v4 **nat_ingress_value_) {
#define BPF_LOG_TOPIC "egress_lookup_or_new_mapping"
    //
    u64 curent_time = bpf_ktime_get_ns();
    struct nat_mapping_key_v4 egress_key = {
        .gress = NAT_MAPPING_EGRESS,
        .l4proto = ip_protocol,                   // 原有的 l4 层协议值
        .from_port = pkt_ip_pair->src_port,       // 数据包中的 内网端口
        .from_addr = pkt_ip_pair->src_addr.addr,  // 内网原始地址
    };

    // 倒置的值
    struct nat_mapping_value_v4 *nat_ingress_value = NULL;
    struct nat_mapping_value_v4 *nat_egress_value =
        bpf_map_lookup_elem(&nat4_mappings, &egress_key);
    if (!nat_egress_value) {
        if (!allow_create_mapping) {
            return TC_ACT_SHOT;
        }
        struct wan_ip_info_key wan_search_key = {0};
        wan_search_key.ifindex = skb->ifindex;
        wan_search_key.l3_protocol = LANDSCAPE_IPV4_TYPE;

        struct wan_ip_info_value *wan_ip_info =
            bpf_map_lookup_elem(&wan_ip_binding, &wan_search_key);

        if (!wan_ip_info) {
            bpf_log_info("can't find the wan ip, using ifindex: %d", skb->ifindex);
            return TC_ACT_SHOT;
        }
        bool allow_reuse_port = get_flow_allow_reuse_port(skb->mark);
        struct nat_mapping_value_v4 new_nat_egress_value = {0};

        new_nat_egress_value.addr = wan_ip_info->addr.ip;
        new_nat_egress_value.port = egress_key.from_port;  // 尽量先试试使用客户端发起时候的端口
        new_nat_egress_value.trigger_addr = pkt_ip_pair->dst_addr.addr;
        new_nat_egress_value.trigger_port = pkt_ip_pair->dst_port;
        new_nat_egress_value.is_static = 0;
        new_nat_egress_value.active_time = curent_time;
        new_nat_egress_value.is_allow_reuse = allow_reuse_port ? 1 : 0;

        int ret;
        struct search_port_ctx_v4 ctx = {
            .ingress_key =
                {
                    .gress = NAT_MAPPING_INGRESS,
                    .l4proto = ip_protocol,
                    .from_addr = new_nat_egress_value.addr,
                    .from_port = new_nat_egress_value.port,
                },
            .curr_port = bpf_ntohs(new_nat_egress_value.port),
            .found = false,
        };

        ctx.timeout_interval = new_nat_egress_value.active_time;
        if (ip_protocol == IPPROTO_TCP) {
            ctx.range.start = tcp_range_start;
            ctx.range.end = tcp_range_end;
            ctx.remaining_size = tcp_range_end - tcp_range_start;
            ctx.timeout_interval -= TCP_TIMEOUT;
        } else if (ip_protocol == IPPROTO_UDP) {
            ctx.range.start = udp_range_start;
            ctx.range.end = udp_range_end;
            ctx.remaining_size = udp_range_end - udp_range_start;
            ctx.timeout_interval -= UDP_TIMEOUT;
        } else if (ip_protocol == IPPROTO_ICMP) {
            ctx.range.start = icmp_range_start;
            ctx.range.end = icmp_range_end;
            ctx.remaining_size = icmp_range_end - icmp_range_start;
            ctx.timeout_interval -= UDP_TIMEOUT;
        }

        if (ctx.remaining_size == 0) {
            bpf_log_error("not free port range start: %d end: %d", ctx.range.start, ctx.range.end);
            return TC_ACT_SHOT;
        }

        if (ctx.curr_port < ctx.range.start || ctx.curr_port > ctx.range.end) {
            u16 index = ctx.curr_port % ctx.remaining_size;
            ctx.curr_port = ctx.range.start + index;
        }

        ret = bpf_loop(65536, search_port_callback_v4, &ctx, 0);
        if (ret < 0) {
            return TC_ACT_SHOT;
        }

        if (ctx.found) {
            new_nat_egress_value.port = ctx.ingress_key.from_port;
        } else {
            bpf_log_debug("mapping is full");
            return TC_ACT_SHOT;
        }
        nat_egress_value =
            insert_mappings_v4(&egress_key, &new_nat_egress_value, &nat_ingress_value);
        if (!nat_egress_value) {
            return TC_ACT_SHOT;
        }
    } else {
        // 已经存在就查询另外一个值 并进行刷新时间
        struct nat_mapping_key_v4 ingress_key = {
            .gress = NAT_MAPPING_INGRESS,
            .l4proto = ip_protocol,               // 原有的 l4 层协议值
            .from_port = nat_egress_value->port,  // 数据包中的 内网端口
            .from_addr = nat_egress_value->addr,  // 内网原始地址
        };
        nat_ingress_value = bpf_map_lookup_elem(&nat4_mappings, &ingress_key);

        if (!nat_ingress_value) {
            return TC_ACT_SHOT;
        }
        nat_egress_value->active_time = nat_ingress_value->active_time = curent_time;
    }

    *nat_egress_value_ = nat_egress_value;
    *nat_ingress_value_ = nat_ingress_value;
    return TC_ACT_OK;
#undef BPF_LOG_TOPIC
}

#endif /* LD_NAT_V4_H */
